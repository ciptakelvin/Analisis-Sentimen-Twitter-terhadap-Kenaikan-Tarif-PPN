{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49d285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPN Naik  processing 254/1000000000...\n"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sns\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def initialize():\n",
    "    #API Initialization\n",
    "    global api_key,api_secret,bearer_token,access_token,token_secret\n",
    "    api_key=os.environ['T_API_KEY']\n",
    "    api_secret=os.environ['T_API_SECRET']\n",
    "    bearer_token=os.environ['T_BEARER_TOKEN']\n",
    "    access_token=os.environ['T_ACCESS_TOKEN']\n",
    "    token_secret=os.environ['T_TOKEN_SECRET']\n",
    "\n",
    "def auth_handler():\n",
    "    #API Auth\n",
    "    global auth,api\n",
    "    auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "    auth.set_access_token(access_token, token_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "def pull(keyword:str,limit:int)->pd.DataFrame:\n",
    "    #Tweet Pull\n",
    "    print(keyword,\" is processing..\")\n",
    "    r=_sns_pull(keyword,limit)\n",
    "    clear_output()\n",
    "    return r\n",
    "\n",
    "def _sns_pull(keyword,limit):\n",
    "    tweet=[]\n",
    "    for i, t in enumerate(sns.TwitterSearchScraper(keyword).get_items()):\n",
    "        clear_output()\n",
    "        print(keyword,\" processing tweet(\"+str(i)+\")...\")\n",
    "        if i>=limit:\n",
    "            break;\n",
    "        \n",
    "        tweet.append([t.id,keyword,t.url,t.date,t.rawContent,None,t.user.username,int(t.viewCount) if t.viewCount else 0,t.replyCount,t.retweetCount,t.likeCount,t.quoteCount,t.lang,t.sourceLabel,t.coordinates.latitude if t.coordinates else None,t.coordinates.longitude if t.coordinates else None,t.place.fullName if t.place else None,t.hashtags,t.inReplyToUser.username if t.inReplyToUser else None,len(t.mentionedUsers) if t.mentionedUsers else 0,[i.username for i in t.mentionedUsers] if t.mentionedUsers else None,t.user.verified,t.user.followersCount,t.user.statusesCount])\n",
    "    return pd.DataFrame(tweet,columns=['Id','Search Keyword','URL','Datetime','Tweet','Sentiment Label','Username','View Count','Reply Count','Retweet Count','Like Count','Quote Count','Language','Source','Coordinates (Latitude)','Coordinates (Longitude)','Place','Hashtags','Reply to User','Mentioned Users Count','Mentioned Users','User Verified','User Followers Count','User Statuses Count'])\n",
    "\n",
    "# def _tw_pull(keyword,limit)->pd.DataFrame:\n",
    "#     tweet=[]\n",
    "    \n",
    "#     for i, t in enumerate(sns.TwitterSearchScraper(keyword).get_items()):\n",
    "#         if i>=limit:\n",
    "#             break;\n",
    "#         tw=api.get_status(t.id)._json\n",
    "#         tweet.append([t.id,keyword,t.url,t.date,t.rawContent,None,t.user.username,t.viewCount,t.replyCount,t.retweetCount,t.likeCount,t.quoteCount,t.lang,t.sourceLabel,t.coordinates.latitude if t.coordinates else None,t.coordinates.longitude if t.coordinates else None,t.place.fullName if t.place else None,t.hashtags,t.inReplyToUser.username if t.inReplyToUser else None,len(t.mentionedUsers) if t.mentionedUsers else 0,[i.username for i in t.mentionedUsers] if t.mentionedUsers else None,t.user.verified,t.user.followersCount,t.user.statusesCount])\n",
    "#     return pd.DataFrame(tweet,columns=['Id','Search Keyword','URL','Datetime','Tweet','Sentiment Label','Username','View Count','Reply Count','Retweet Count','Like Count','Quote Count','Language','Source','Coordinates (Latitude)','Coordinates (Longitude)','Place','Hashtags','Reply to User','Mentioned Users Count','Mentioned Users','User Verified','User Followers Count','User Statuses Count'])\n",
    "\n",
    "def multi_pull(data:list[pd.DataFrame])->pd.DataFrame:\n",
    "    d=data[0]\n",
    "    for k,i in enumerate(data):\n",
    "        if k==0:\n",
    "            continue\n",
    "        d=pd.concat([d,i],ignore_index=True).copy()\n",
    "    return d\n",
    "\n",
    "#Initialization\n",
    "initialize()\n",
    "auth_handler()\n",
    "\n",
    "#Setting\n",
    "file_name=\"PPN Naik\"\n",
    "tweet_limit=1000000000\n",
    "keywords=[\n",
    "    \"PPN Naik\",\n",
    "    \"PPN 11%\",\n",
    "    \"Kenaikan PPN\",\n",
    "    \"Tarif baru PPN\"\n",
    "]\n",
    "\n",
    "#Pull Tweet\n",
    "data=multi_pull([pull(i,tweet_limit) for i in keywords])\n",
    "\n",
    "#Save to CSV\n",
    "data.to_csv(str(datetime.now()).replace(\":\",\".\")+\" \"+file_name+\".csv\",index=False)\n",
    "print(\"File Saved\")\n",
    "data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
