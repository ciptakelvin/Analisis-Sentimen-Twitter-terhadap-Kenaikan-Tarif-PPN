{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "75e42ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 4555 features, but DecisionTreeClassifier is expecting 1071 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 170\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m#Predict\u001b[39;00m\n\u001b[0;32m    169\u001b[0m ana\u001b[38;5;241m=\u001b[39mAnalyzer()\n\u001b[1;32m--> 170\u001b[0m \u001b[43mana\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# data[\"Clean\"]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[81], line 98\u001b[0m, in \u001b[0;36mAnalyzer.predict\u001b[1;34m(self, model, data)\u001b[0m\n\u001b[0;32m     96\u001b[0m X\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[:,data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m!=\u001b[39mdata\u001b[38;5;241m.\u001b[39mcolumns[target_column]]\n\u001b[0;32m     97\u001b[0m y\u001b[38;5;241m=\u001b[39mdata[data\u001b[38;5;241m.\u001b[39mcolumns[target_column]]\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:426\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    425\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 426\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    428\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:392\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[1;32m--> 392\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    394\u001b[0m         X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc\n\u001b[0;32m    395\u001b[0m     ):\n\u001b[0;32m    396\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:558\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    555\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:359\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 4555 features, but DecisionTreeClassifier is expecting 1071 features as input."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import csv\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump, load\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "#Import Classifier Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "class Preprocessor():\n",
    "    def __init__(self,text):\n",
    "        \"\"\"\n",
    "        Preprocessing Text: Digunakan untuk membersihkan teks sebelum dilakukan analisis.\n",
    "        mencakup proses casefolding, filtering\n",
    "        \"\"\"\n",
    "        self.text=text\n",
    "        self._casefolding()\n",
    "        self._filtering()\n",
    "        self._tokenize()\n",
    "        self._standarize()\n",
    "#         self._stemming()\n",
    "\n",
    "    def get_text(self):\n",
    "        return \" \".join(self.text)\n",
    "    \n",
    "    def _casefolding(self):\n",
    "        #Mengubah menjadi huruf kecil        \n",
    "        self.text=self.text.lower()\n",
    "    \n",
    "    def _filtering(self):        \n",
    "        #Url\n",
    "        self.text=re.sub(\"https\\S+\",\"\",self.text)\n",
    "        self.text=re.sub(\"http\\S+\",\"\",self.text)\n",
    "        self.text=re.sub(\"\\S+\\.com\\S+\",\"\",self.text)\n",
    "        self.text=re.sub(\"\\S+\\.com\",\"\",self.text)\n",
    "        \n",
    "        #Hashtag\n",
    "        self.text=re.sub(\"#\\S+\",\"\",self.text)\n",
    "        \n",
    "        #Mention\n",
    "        self.text=re.sub(\"@\\S+\",\"\",self.text)\n",
    "        \n",
    "        #Symbol and Number\n",
    "        self.text=re.sub(\"[^A-Za-z\\s]\",\"\",self.text)\n",
    "        \n",
    "        #Spacing\n",
    "        self.text=re.sub(\"\\s+\",\" \",self.text)\n",
    "        self.text=re.sub(\"^\\s\",\"\",self.text)\n",
    "        self.text=self.text\n",
    "    \n",
    "    def _tokenize(self):\n",
    "        #Membagi kata\n",
    "        self.text=word_tokenize(self.text)\n",
    "\n",
    "    def _standarize(self):        \n",
    "        #Mengubah menjadi kata baku\n",
    "        j={}\n",
    "        with open(\"standard_word.csv\",\"r\") as file:\n",
    "            data=csv.reader(file,delimiter=\",\")\n",
    "            for k,i in enumerate(data):\n",
    "                if k==0: continue\n",
    "                j[i[0]]=i[1]\n",
    "                \n",
    "        for k,t in enumerate(self.text):\n",
    "            if t in j:\n",
    "                self.text[k]=j[t]\n",
    "    \n",
    "    def _stemming(self):        \n",
    "        factory=StemmerFactory()\n",
    "        stemmer=factory.create_stemmer()\n",
    "        \n",
    "        for k,i in enumerate(self.text):\n",
    "            self.text[k]=stemmer.stem(i)\n",
    "    \n",
    "class Analyzer():  \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self,model,data:pd.DataFrame):\n",
    "        target_column:int=len(data.columns)-1\n",
    "        X=data.iloc[:,data.columns!=data.columns[target_column]]\n",
    "        y=data[data.columns[target_column]]\n",
    "        return model.predict(X)\n",
    "    \n",
    "    def train_model(self,model,data:pd.DataFrame):\n",
    "        target_column:int=len(data.columns)-1\n",
    "        X=data.iloc[:,data.columns!=data.columns[target_column]]\n",
    "        y=data[data.columns[target_column]]\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "        \n",
    "        models_used=[\n",
    "            KNeighborsClassifier(),\n",
    "            SVC(),\n",
    "            GaussianNB(),\n",
    "            MultinomialNB(),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            GradientBoostingClassifier(),\n",
    "        ]\n",
    "        model.fit(X_train,y_train)\n",
    "        prediction=model.predict(X_test)\n",
    "        if accuracy_score(prediction,y_test)>0.9:\n",
    "            print(\"Model has beed trained with new data and saved using \"+model.__class__.__name__+\" model. Accuracy Score: \",accuracy_score(prediction,y_test))\n",
    "            dump(model,\"models/\"+model.__class__.__name__+\" \"+str(datetime.now()).replace(\":\",\"\")+\".joblib\")\n",
    "        else:\n",
    "            print(\"Data is not good enough. Model is not saved. Accuracy score: \",accuracy_score(prediction,y_test))\n",
    "        \n",
    "    def create_model(self,data:pd.DataFrame):\n",
    "        target_column:int=len(data.columns)-1\n",
    "        X=data.iloc[:,data.columns!=data.columns[target_column]]\n",
    "        y=data[data.columns[target_column]]\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "        \n",
    "        models_used=[\n",
    "            KNeighborsClassifier(),\n",
    "            SVC(),\n",
    "            GaussianNB(),\n",
    "            MultinomialNB(),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            GradientBoostingClassifier(),\n",
    "        ]\n",
    "        \n",
    "        max_accuracy=0\n",
    "        for i in models_used:\n",
    "            i.fit(X_train,y_train)\n",
    "            prediction=i.predict(X_test)\n",
    "            accuracy=accuracy_score(prediction,y_test)\n",
    "            \n",
    "            if accuracy>max_accuracy:\n",
    "                max_accuracy=accuracy\n",
    "                model=i\n",
    "            print(i,prediction)\n",
    "            print(\"Accuracy Score:\",accuracy,\"\\n\")\n",
    "        \n",
    "        print(\"Model saved using \"+model.__class__.__name__+\" model. Accuracy: \"+str(max_accuracy))\n",
    "        dump(model,\"models/\"+model.__class__.__name__+\" \"+str(datetime.now()).replace(\":\",\"\")+\".joblib\")\n",
    "\n",
    "#Load Model\n",
    "model=load('models/DecisionTreeClassifier 2023-02-28 005926.237284.joblib')\n",
    "\n",
    "#Load Data\n",
    "data=pd.read_csv('data/2023-02-27 08.24.25.743067 Keywords pajak.csv')\n",
    "\n",
    "#Preprocessing\n",
    "data[\"Clean\"]=[Preprocessor(i).get_text() for i in data[\"Tweet\"]]\n",
    "\n",
    "#TFIDF Calculation\n",
    "vect=TfidfVectorizer()\n",
    "X=vect.fit_transform(data[\"Clean\"])\n",
    "df=pd.DataFrame(X.toarray())\n",
    "\n",
    "#Predict\n",
    "ana=Analyzer()\n",
    "ana.predict(model,df)\n",
    "# data[\"Clean\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
