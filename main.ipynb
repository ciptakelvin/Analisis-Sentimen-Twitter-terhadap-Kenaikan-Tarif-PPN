{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75e42ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing.. Accuracy Score:  0.5491803278688525\n",
      "Testing.. Accuracy Score:  0.6147540983606558\n",
      "Testing.. Accuracy Score:  0.6311475409836066\n",
      "Testing.. Accuracy Score:  0.6557377049180327\n",
      "Testing.. Accuracy Score:  0.6721311475409836\n",
      "Testing.. Accuracy Score:  0.6475409836065574\n",
      "Testing.. Accuracy Score:  0.5901639344262295\n",
      "Testing.. Accuracy Score:  0.6639344262295082\n",
      "Testing.. Accuracy Score:  0.5655737704918032\n",
      "Testing.. Accuracy Score:  0.6557377049180327\n",
      "KNeighborsClassifier() [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1.]\n",
      "Average Accuracy Score: 0.6245901639344262 \n",
      "\n",
      "Testing.. Accuracy Score:  0.6885245901639344\n",
      "Testing.. Accuracy Score:  0.7131147540983607\n",
      "Testing.. Accuracy Score:  0.6639344262295082\n",
      "Testing.. Accuracy Score:  0.6557377049180327\n",
      "Testing.. Accuracy Score:  0.680327868852459\n",
      "Testing.. Accuracy Score:  0.6639344262295082\n",
      "Testing.. Accuracy Score:  0.6639344262295082\n",
      "Testing.. Accuracy Score:  0.6639344262295082\n",
      "Testing.. Accuracy Score:  0.6475409836065574\n",
      "Testing.. Accuracy Score:  0.680327868852459\n",
      "SVC() [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "Average Accuracy Score: 0.6721311475409836 \n",
      "\n",
      "Testing.. Accuracy Score:  0.319672131147541\n",
      "Testing.. Accuracy Score:  0.45081967213114754\n",
      "Testing.. Accuracy Score:  0.09836065573770492\n",
      "Testing.. Accuracy Score:  0.45081967213114754\n",
      "Testing.. Accuracy Score:  0.07377049180327869\n",
      "Testing.. Accuracy Score:  0.5245901639344263\n",
      "Testing.. Accuracy Score:  0.4672131147540984\n",
      "Testing.. Accuracy Score:  0.3442622950819672\n",
      "Testing.. Accuracy Score:  0.4180327868852459\n",
      "Testing.. Accuracy Score:  0.06557377049180328\n",
      "GaussianNB() [1. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 2. 1. 2. 1. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2.]\n",
      "Average Accuracy Score: 0.32131147540983607 \n",
      "\n",
      "Testing.. Accuracy Score:  0.5081967213114754\n",
      "Testing.. Accuracy Score:  0.5819672131147541\n",
      "Testing.. Accuracy Score:  0.5245901639344263\n",
      "Testing.. Accuracy Score:  0.5819672131147541\n",
      "Testing.. Accuracy Score:  0.4098360655737705\n",
      "Testing.. Accuracy Score:  0.5737704918032787\n",
      "Testing.. Accuracy Score:  0.639344262295082\n",
      "Testing.. Accuracy Score:  0.48360655737704916\n",
      "Testing.. Accuracy Score:  0.4426229508196721\n",
      "Testing.. Accuracy Score:  0.47540983606557374\n",
      "MultinomialNB() [1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 2. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 2. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 0. 1. 1. 1. 0. 0. 0. 2. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 2. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 2. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 2. 0. 0. 1. 1. 0. 0. 0. 2. 1. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "Average Accuracy Score: 0.5221311475409837 \n",
      "\n",
      "Testing.. Accuracy Score:  0.6311475409836066\n",
      "Testing.. Accuracy Score:  0.5901639344262295\n",
      "Testing.. Accuracy Score:  0.6065573770491803\n",
      "Testing.. Accuracy Score:  0.5655737704918032\n",
      "Testing.. Accuracy Score:  0.639344262295082\n",
      "Testing.. Accuracy Score:  0.5983606557377049\n",
      "Testing.. Accuracy Score:  0.5737704918032787\n",
      "Testing.. Accuracy Score:  0.5573770491803278\n",
      "Testing.. Accuracy Score:  0.5737704918032787\n",
      "Testing.. Accuracy Score:  0.5081967213114754\n",
      "DecisionTreeClassifier() [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1.]\n",
      "Average Accuracy Score: 0.5844262295081968 \n",
      "\n",
      "Testing.. Accuracy Score:  0.6065573770491803\n",
      "Testing.. Accuracy Score:  0.5163934426229508\n",
      "Testing.. Accuracy Score:  0.639344262295082\n",
      "Testing.. Accuracy Score:  0.6311475409836066\n",
      "Testing.. Accuracy Score:  0.5983606557377049\n",
      "Testing.. Accuracy Score:  0.5901639344262295\n",
      "Testing.. Accuracy Score:  0.639344262295082\n",
      "Testing.. Accuracy Score:  0.5901639344262295\n",
      "Testing.. Accuracy Score:  0.639344262295082\n",
      "Testing.. Accuracy Score:  0.5819672131147541\n",
      "RandomForestClassifier() [0. 0. 2. 2. 0. 0. 1. 2. 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 2. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 2. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 2. 0. 0. 1. 1. 0. 0. 0. 2. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 2.]\n",
      "Average Accuracy Score: 0.6032786885245902 \n",
      "\n",
      "Testing.. Accuracy Score:  0.6147540983606558\n",
      "Testing.. Accuracy Score:  0.6147540983606558\n",
      "Testing.. Accuracy Score:  0.6229508196721312\n",
      "Testing.. Accuracy Score:  0.5901639344262295\n",
      "Testing.. Accuracy Score:  0.6065573770491803\n",
      "Testing.. Accuracy Score:  0.639344262295082\n",
      "Testing.. Accuracy Score:  0.5409836065573771\n",
      "Testing.. Accuracy Score:  0.5655737704918032\n",
      "Testing.. Accuracy Score:  0.5983606557377049\n",
      "Testing.. Accuracy Score:  0.6311475409836066\n",
      "GradientBoostingClassifier() [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 2. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0.]\n",
      "Average Accuracy Score: 0.6024590163934426 \n",
      "\n",
      "Model used: SVC model. Accuracy: 0.6721311475409836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28796"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import csv\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump, load\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "#Import Classifier Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "class Preprocessor():\n",
    "    def __init__(self,text):\n",
    "        \"\"\"\n",
    "        Preprocessing Text: Digunakan untuk membersihkan teks sebelum dilakukan analisis.\n",
    "        mencakup proses casefolding, filtering\n",
    "        \"\"\"\n",
    "        self.text=text\n",
    "        self._casefolding()\n",
    "        self._filtering()\n",
    "        self._tokenize()\n",
    "        self._standarize()\n",
    "        self._stemming()\n",
    "\n",
    "    def get_text(self):\n",
    "        return \" \".join(self.text)\n",
    "    \n",
    "    def _casefolding(self):\n",
    "        #Mengubah menjadi huruf kecil        \n",
    "        self.text=self.text.lower()\n",
    "    \n",
    "    def _filtering(self):        \n",
    "        #Url\n",
    "        self.text=re.sub(\"https\\S+\",\"\",self.text)\n",
    "        self.text=re.sub(\"http\\S+\",\"\",self.text)\n",
    "        self.text=re.sub(\"\\S+\\.com\\S+\",\"\",self.text)\n",
    "        self.text=re.sub(\"\\S+\\.com\",\"\",self.text)\n",
    "        \n",
    "        #Remove Hashtag\n",
    "        self.text=re.sub(\"#\\S+\",\"\",self.text)\n",
    "        \n",
    "        #Remove Mention\n",
    "        self.text=re.sub(\"@\\S+\",\"\",self.text)\n",
    "        \n",
    "        #Remove Symbol and Number\n",
    "        self.text=re.sub(\"[^A-Za-z\\s]\",\" \",self.text)\n",
    "        \n",
    "        #Remove Spacing\n",
    "        self.text=re.sub(\"\\s+\",\" \",self.text)\n",
    "        self.text=re.sub(\"^\\s\",\"\",self.text)\n",
    "        self.text=self.text\n",
    "    \n",
    "    def _tokenize(self):\n",
    "        #Membagi kata\n",
    "        self.text=word_tokenize(self.text)\n",
    "\n",
    "    def _standarize(self):        \n",
    "        #Mengubah menjadi kata baku\n",
    "        j={}\n",
    "        with open(\"standard_word.csv\",\"r\") as file:\n",
    "            data=csv.reader(file,delimiter=\",\")\n",
    "            for k,i in enumerate(data):\n",
    "                if k==0: continue\n",
    "                j[i[0]]=i[1]\n",
    "                \n",
    "        for k,t in enumerate(self.text):\n",
    "            if t in j:\n",
    "                self.text[k]=j[t]\n",
    "    \n",
    "    def _stemming(self):\n",
    "        #Mengubah menjadi kata dasar\n",
    "        factory=StemmerFactory()\n",
    "        stemmer=factory.create_stemmer()\n",
    "        \n",
    "        for k,i in enumerate(self.text):\n",
    "            self.text[k]=stemmer.stem(i)\n",
    "    \n",
    "class Analyzer():  \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Membuat model dan melakukan prediksi\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self,training_data:pd.DataFrame,data_to_predict:pd.DataFrame):\n",
    "        model=self.create_model(training_data)\n",
    "        return self.predict_by_model(model,data_to_predict)\n",
    "    \n",
    "    def predict_by_model(self,model,data:pd.DataFrame):\n",
    "\n",
    "        #Output Data\n",
    "        target_column:int=len(data.columns)-1\n",
    "        X=data.iloc[:,data.columns!=data.columns[target_column]]\n",
    "        y=data[data.columns[target_column]]\n",
    "        prediction=model.predict(X)\n",
    "        return prediction\n",
    "    \n",
    "        \n",
    "    def create_model(self,data:pd.DataFrame,is_save:bool=False):\n",
    "        target_column:int=len(data.columns)-1\n",
    "        X=data.iloc[:,data.columns!=data.columns[target_column]]\n",
    "        y=data[data.columns[target_column]]\n",
    "        \n",
    "        models_used=[\n",
    "            KNeighborsClassifier(),\n",
    "            SVC(),\n",
    "            GaussianNB(),\n",
    "            MultinomialNB(),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            GradientBoostingClassifier(),\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        max_accuracy=0\n",
    "        for i in models_used:\n",
    "            accuracies=[]\n",
    "            for j in range(10):\n",
    "                X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5)\n",
    "                i.fit(X_train,y_train)\n",
    "                prediction=i.predict(X_test)\n",
    "                accuracies.append(accuracy_score(prediction,y_test))\n",
    "                print(\"Testing.. Accuracy Score: \",accuracy_score(prediction,y_test))\n",
    "            \n",
    "            accuracy=np.average(accuracies)\n",
    "            if accuracy>max_accuracy:\n",
    "                max_accuracy=accuracy\n",
    "                model=i\n",
    "            print(i,prediction)\n",
    "            print(\"Average Accuracy Score:\",accuracy,\"\\n\")\n",
    "        \n",
    "#         max_accuracy=0\n",
    "#         for i in models_used:\n",
    "#             i.fit(X_train,y_train)\n",
    "#             prediction=i.predict(X_test)\n",
    "#             accuracy=accuracy_score(prediction,y_test)\n",
    "            \n",
    "#             if accuracy>max_accuracy:\n",
    "#                 max_accuracy=accuracy\n",
    "#                 model=i\n",
    "#             print(i,prediction)\n",
    "#             print(\"Accuracy Score:\",accuracy,\"\\n\")\n",
    "        \n",
    "        print(\"Model used: \"+model.__class__.__name__+\" model. Accuracy: \"+str(max_accuracy))\n",
    "        if is_save:\n",
    "            dump(model,\"models/\"+model.__class__.__name__+\" \"+str(datetime.now()).replace(\":\",\"\")+\".joblib\")\n",
    "        return model\n",
    "\n",
    "def check_tweet(order):\n",
    "    tweet=data[\"Tweet\"][order]\n",
    "    pre=Preprocessor(tweet)\n",
    "    return \"Tweet order: \"+str(order)+\" Tweet: \"+pre.get_text()\n",
    "\n",
    "def check_random_tweet():\n",
    "    order=random.randint(0,len(data[\"Tweet\"])-1)\n",
    "    tweet=data[\"Tweet\"][order]\n",
    "    pre=Preprocessor(tweet)\n",
    "    return \"Tweet order: \"+str(order)+\" Tweet: \"+pre.get_text()\n",
    "\n",
    "# #Load Data\n",
    "full=pd.read_csv('data/clean.csv') #Full Data\n",
    "full[\"Label\"]=0\n",
    "labeled=pd.read_csv('data/labeled.csv') #Labeled Data\n",
    "\n",
    "#Select Labeled Data to Train and Predict\n",
    "df=labeled[labeled[\"Label\"].notnull()]\n",
    "train_data=df.iloc[:,[6,7,8,9,10,20,21,27]]\n",
    "data_to_predict=full.iloc[:,[6,7,8,9,10,20,21,27]]\n",
    "\n",
    "#Create Best Model\n",
    "# ana=Analyzer()\n",
    "# ana.create_model(ana_df)\n",
    "\n",
    "#Load Model\n",
    "# model=load('models/SVC 2023-04-03 215442.101498.joblib')\n",
    "# ana=Analyzer()\n",
    "# ana.predict_by_model(model,full.iloc[:,[6,7,8,9,10,20,21,27]])\n",
    "\n",
    "#Direct Data Predict from Labled Data\n",
    "ana=Analyzer()\n",
    "prediction=ana.predict(train_data,data_to_predict) #Return Prediction Array\n",
    "len(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
